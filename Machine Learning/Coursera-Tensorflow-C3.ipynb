{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# ⚜️ 《C3 Natural Language Processing》"
      ],
      "metadata": {
        "id": "Cmbes9S-gmPq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 文本的情感\n",
        "\n",
        "#### 基于单词的编码\n",
        "\n",
        "给第一个单词一个编码  \n",
        "```\n",
        "I Love My Dog.\n",
        "1 2    3  4\n",
        "I Love My Cat.\n",
        "1 2    3  5\n",
        "==>\n",
        "My Cat Love Me\n",
        "3  5   2    6\n",
        "```\n",
        "\n"
      ],
      "metadata": {
        "id": "IalcHa9D2BXm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 标记化 Tokenization\n",
        "在 TensorFlow NLP 中，单词或词汇通常会被转换成以下两种形式之一：  \n",
        "\t1.\t词级 (Word-level) 编码\n",
        "\t•\t每个单词被映射为一个唯一的整数 ID。\n",
        "\t•\t示例：{\"I\": 1, \"Love\": 2, \"My\": 3, \"Dog\": 4, \"Cat\": 5}\n",
        "\n",
        "\t2.\t子词级 (Subword-level) 编码（更推荐）\n",
        "\t•\t句子被拆解成更小的子词单元（如 BERT 的 WordPiece、GPT 的 Byte-Pair Encoding 等）。   \n",
        "文本示例： \"unbelievably fast\"   \n",
        "\n",
        "| 编码等级 | 编码示例 |    \n",
        "|:--------|:-------|  \n",
        "| 词级 | unbelievably=100, fast = 101 |  \n",
        "| 子词级 | un=1, believ=2, ably=3, fast=4 |  \n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "lrrZlhDZ5gbX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "sentences = [\n",
        "    'I love my dog',\n",
        "    'I love my cat',\n",
        "    'You love my dog!',\n",
        "    'Do you think my dog is amazing?'\n",
        "    ]\n",
        "\n",
        "vectorize_layer = tf.keras.layers.TextVectorization()\n",
        "vectorize_layer.adapt(sentences)\n",
        "vocabulary = vectorize_layer.get_vocabulary()\n",
        "print(vocabulary)\n",
        "vocab = vectorize_layer.get_vocabulary(include_special_tokens=False)\n",
        "print(vocab)"
      ],
      "metadata": {
        "id": "S2QQeH1XbFvi",
        "outputId": "ffb275ce-9d2a-4803-a58b-c0b117957ddf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['', '[UNK]', 'my', 'love', 'dog', 'you', 'i', 'think', 'is', 'do', 'cat', 'amazing']\n",
            "['my', 'love', 'dog', 'you', 'i', 'think', 'is', 'do', 'cat', 'amazing']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 将句子 矢量化\n",
        "test_new_seq = vectorize_layer(\"I LOVE My Bird\")\n",
        "print(test_new_seq) ## 注意unknown word--bird，在seq将使用句子中没有出现过的token替换\n",
        "\n",
        "# 矢量化数组\n",
        "test_arr_seq = vectorize_layer(['I love my son', 'My Son Love Me'])\n",
        "print(test_arr_seq)\n",
        "\n",
        "# 矢量化为map\n",
        "sentence_dataset = tf.data.Dataset.from_tensor_slices(sentences)\n",
        "sequences = sentence_dataset.map(vectorize_layer)\n",
        "for sentence, sequence in zip(sentences, sequences):\n",
        "  print(f'{sentence} ---> {sequence}')"
      ],
      "metadata": {
        "id": "pYNB2Xzcb_KB",
        "outputId": "22cccfff-b1a3-49de-d639-c2b38a1680cb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor([6 3 2 1], shape=(4,), dtype=int64)\n",
            "tf.Tensor(\n",
            "[[6 3 2 1]\n",
            " [2 1 3 1]], shape=(2, 4), dtype=int64)\n",
            "I love my dog ---> [6 3 2 4]\n",
            "I love my cat ---> [ 6  3  2 10]\n",
            "You love my dog! ---> [5 3 2 4]\n",
            "Do you think my dog is amazing? ---> [ 9  5  7  2  4  8 11]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 将句子对齐 (默认右对齐，左边补0)\n",
        "sequences_pre = tf.keras.utils.pad_sequences(sequences=sequences)\n",
        "print(sequences_pre)\n",
        "\n",
        "# 示例右边补0，截断仅保留5位\n",
        "sequences_post = tf.keras.utils.pad_sequences(sequences=sequences, padding='post', maxlen=5, truncating='post')\n",
        "print(sequences_post)"
      ],
      "metadata": {
        "id": "h5cJvOQLd28C",
        "outputId": "c0c10a04-7aa0-4fd7-b7c1-557f456b2795",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[ 0  0  0  6  3  2  4]\n",
            " [ 0  0  0  6  3  2 10]\n",
            " [ 0  0  0  5  3  2  4]\n",
            " [ 9  5  7  2  4  8 11]]\n",
            "[[ 6  3  2  4  0]\n",
            " [ 6  3  2 10  0]\n",
            " [ 5  3  2  4  0]\n",
            " [ 9  5  7  2  4]]\n"
          ]
        }
      ]
    }
  ]
}