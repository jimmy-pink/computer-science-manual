{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jimmy-pink/computer-science-manual/blob/main/Machine-Learning/PyTorch-%E5%85%A5%E9%97%A8-%E5%BC%A0%E9%87%8F.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "QaZ_xmJ9biey"
      },
      "cell_type": "markdown",
      "source": [
        "## 张量 Tensor\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "# 标量 0d\n",
        "x_0 = 3.14\n",
        "print(\"标量：\", x_0)\n",
        "# 向量 1d\n",
        "x = torch.arange(6)\n",
        "x_ones = torch.ones(3)\n",
        "x_zeros = torch.zeros(3)\n",
        "print(\"向量：\", x, \"，全一向量\", x_ones, \"，零向量：\", x_zeros)\n",
        "# 矩阵 2d\n",
        "X = torch.tensor([[1,2,3,4],[5,6,7,8]],dtype=torch.int)\n",
        "print(\"矩阵：\", X)\n",
        "# 3阶张量\n",
        "rgb_tensor = torch.tensor([\n",
        "    [[255,   0],  [  0, 255]],  # R通道（红色值）\n",
        "    [[  0, 255],  [255,   0]],  # G通道（绿色值）\n",
        "    [[  0,   0],  [255, 255]],  # B通道（蓝色值）\n",
        "], dtype=torch.uint8)\n",
        "print(\"3阶张量的shape: \", rgb_tensor.shape)\n",
        "print(\"3阶张量：\", rgb_tensor)"
      ],
      "metadata": {
        "id": "-rsiK0NqboJY",
        "outputId": "f3b261df-dfda-4ed2-ff0e-aeb28980adb5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "标量： 3.14\n",
            "向量： tensor([0, 1, 2, 3, 4, 5]) ，全一向量 tensor([1., 1., 1.]) ，零向量： tensor([0., 0., 0.])\n",
            "矩阵： tensor([[1, 2, 3, 4],\n",
            "        [5, 6, 7, 8]], dtype=torch.int32)\n",
            "3阶张量的shape:  torch.Size([3, 2, 2])\n",
            "3阶张量： tensor([[[255,   0],\n",
            "         [  0, 255]],\n",
            "\n",
            "        [[  0, 255],\n",
            "         [255,   0]],\n",
            "\n",
            "        [[  0,   0],\n",
            "         [255, 255]]], dtype=torch.uint8)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 访问张量的元素或子集\n",
        "\n",
        "四阶张量的命名： batch, channels, rows, columns"
      ],
      "metadata": {
        "id": "0FdDYvqbjWcU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "img_t = torch.randn(4, 5, 5) # shape [channels, rows, columns]\n",
        "\n",
        "print(\"访问向量的第2个元素：\", x[2])\n",
        "print(\"访问矩阵第1行第2列那个元素：\", X[1][2])\n",
        "print(\"访问颜色张量第2通道第1行第1列那个元素：\", rgb_tensor[2,1,1])\n",
        "print(\"访问颜色张量的一块连续子区域：\", rgb_tensor[1:3,0:2])\n",
        "print(\"3阶张量：\", img_t)\n",
        "print(\"访问3阶张量的一块不连续子区域：\", img_t[0:4:3,1:5:2,1:5:2])"
      ],
      "metadata": {
        "id": "JN7ZVHLKjbrq",
        "outputId": "915c72de-67e5-4f59-ef41-92fb9ac75244",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "访问向量的第2个元素： tensor(2)\n",
            "访问矩阵第1行第2列那个元素： tensor(7, dtype=torch.int32)\n",
            "访问颜色张量第2通道第1行第1列那个元素： tensor(255, dtype=torch.uint8)\n",
            "访问颜色张量的一块连续子区域： tensor([[[  0, 255],\n",
            "         [255,   0]],\n",
            "\n",
            "        [[  0,   0],\n",
            "         [255, 255]]], dtype=torch.uint8)\n",
            "3阶张量： tensor([[[-0.3110, -0.9756, -1.2022,  1.2288, -0.7654],\n",
            "         [-1.4895, -1.9921,  1.8830, -0.7383,  0.3264],\n",
            "         [-1.7036,  0.9096,  0.2310, -1.9789,  0.2010],\n",
            "         [-1.2698,  0.8001, -0.3388,  0.5808, -0.8155],\n",
            "         [ 0.3885, -0.1499,  1.6647,  1.6144, -1.0663]],\n",
            "\n",
            "        [[-0.4257,  0.6621,  1.2457,  0.4879, -0.0656],\n",
            "         [ 0.2715,  0.1006,  0.7760,  0.8289, -1.6803],\n",
            "         [-0.1898,  0.6343,  0.3446,  0.4266,  0.2590],\n",
            "         [ 2.3556, -0.1518, -0.4877,  1.3065, -1.3524],\n",
            "         [ 0.8320, -1.9531, -0.2785, -0.7535,  0.5942]],\n",
            "\n",
            "        [[ 0.6583, -2.1944, -0.3406, -0.8399,  2.6574],\n",
            "         [-0.5084,  1.5626,  1.0451, -0.3923,  2.1799],\n",
            "         [-1.4715,  1.0348, -0.4803,  2.3652, -0.3002],\n",
            "         [ 0.4423,  0.7951, -0.0147,  0.2543, -0.0051],\n",
            "         [ 0.7639,  0.5208,  1.3708,  0.6653,  1.4141]],\n",
            "\n",
            "        [[ 0.4508,  0.3761,  2.0315, -1.2758, -0.9388],\n",
            "         [-0.8596, -1.8437,  0.7378,  0.2832, -1.4039],\n",
            "         [ 0.2400, -0.9691, -0.4226, -0.4359, -0.4286],\n",
            "         [-0.6394, -0.8099, -1.1123, -0.4489,  0.0858],\n",
            "         [-2.1087, -0.7448,  0.2491,  0.8571,  0.4197]]])\n",
            "访问3阶张量的一块不连续子区域： tensor([[[-1.9921, -0.7383],\n",
            "         [ 0.8001,  0.5808]],\n",
            "\n",
            "        [[-1.8437,  0.2832],\n",
            "         [-0.8099, -0.4489]]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 张量元数据： 大小、步长、偏移量"
      ],
      "metadata": {
        "id": "YVeob3JUBv8X"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 大小：描述张量在每个维度的长度，如下四阶张量，Size描述张量的  batch=6，channels=3，rows=4，cols=4\n",
        "x = torch.randn(6,3,4,4)\n",
        "print(\"形状\",x.shape)\n",
        "print(\"维度\", x.ndimension())\n",
        "\n",
        "# 步长：描述在内存中访问张量元素时，每个维度间隔的步长，即从一个元素到下一个元素在内存中所需跳过的元素个数。\n",
        "x = torch.randn(2,3,4)\n",
        "print(\"步长\",x.stride())  # 从通道1访问到通道2时，需要访问3*4个元素； 从行1访问到行2时，需要访问4个元素\n",
        "\n",
        "# 检查张量是否是内存连续的\n",
        "print(\"是否连续\",x.is_contiguous())\n",
        "\n",
        "# 偏移量：张量数据在存储缓冲区中的起始位置\n",
        "print(\"offset\", x.storage_offset())\n",
        "\n",
        "# 元素总数\n",
        "print(\"元素总数\",x.numel())\n",
        "\n",
        "print(\"元素是否浮点数\", x.is_floating_point())\n",
        "\n",
        "print(\"是否是 稀疏 张量\", x.is_sparse) #大多数元素为0？\n"
      ],
      "metadata": {
        "id": "hj1lhC50BwyQ",
        "outputId": "74530e17-5262-4dc4-d99b-9702116d4b3a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "形状 torch.Size([6, 3, 4, 4])\n",
            "维度 4\n",
            "步长 (12, 4, 1)\n",
            "是否连续 True\n",
            "offset 0\n",
            "元素总数 24\n",
            "元素是否浮点数 True\n",
            "是否是 稀疏 张量 False\n",
            "存储在 cpu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 张量的数学计算"
      ],
      "metadata": {
        "id": "H4hUKN7OCJgQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 张量的+-*/\n",
        "x = torch.tensor([1, 2, 3])\n",
        "y = torch.tensor([4, 5, 6])\n",
        "result = x + y  # 结果是 [5, 7, 9]\n",
        "\n",
        "x = torch.tensor([[1], [2], [3]])  # 形状是 (3, 1)\n",
        "y = torch.tensor([4, 5, 6])        # 形状是 (3,)\n",
        "result2 = x - y  # 广播后，结果是 [[5, 6, 7], [7, 8, 9], [9, 10, 11]]\n",
        "result3 = x * y\n",
        "result4 = x / y\n",
        "\n",
        "x = torch.tensor([1, 2, 3])\n",
        "y = torch.tensor([4, 5])  # 形状不匹配，无法广播\n",
        "# x和y不能运算\n",
        "\n",
        "z = torch.matmul(x, y) #矩阵乘法\n",
        "z = torch.mm(x, y) # 2D矩阵乘法\n",
        "z = torch.dot(x, y) # 计算张量的点积\n",
        "z = torch.prod(x) # 所有元素相乘\n",
        "\n",
        "x = torch.tensor([1.0, -2.0, -3.0])\n",
        "# 绝对值\n",
        "x_abs = torch.abs(x)\n",
        "print(x, \"的绝对值张量：\", x_abs)\n",
        "\n",
        "# 是否相等\n",
        "eq = torch.equal(x, x_abs)\n",
        "print(\"张量x和它的绝对值不相等：\", eq)\n",
        "\n",
        "# 计算标准差\n",
        "std = torch.std(x)\n",
        "print(\"标准差：\", std)\n",
        "\n",
        "# 计算张量的范数，用于衡量向量或矩阵的大小、长度或“幅度”，默认是 Frobenius 范数（适用于矩阵），也可以指定 p=1 (所有元素绝对值之和) 等。\n",
        "norm = torch.norm(x)\n",
        "print(\"X的范数：\", norm)\n",
        "\n",
        "# 计算张量所有元素的平均值、最大，最小值\n",
        "x = torch.tensor([[1,2,3],[4,5,6]], dtype=torch.float)\n",
        "avg = torch.mean(x)\n",
        "min = torch.min(x)\n",
        "max = torch.max(x)\n",
        "print(\"AVG:\", avg,\",MAX:\",max,\",MIN:\",min, \"SUM:\", torch.sum(x))\n",
        "\n",
        "# 生成正态分布的随机数\n",
        "x = torch.normal(mean=0.0, std=1.0, size=(3,))\n",
        "print(\"正态分布随机数：\", x)\n",
        "\n",
        "\n",
        "# 计算两个张量的叉乘（3D 向量），常用于计算向量正交方向。\n",
        "a = torch.tensor([1.0, 0.0, 0.0])\n",
        "b = torch.tensor([0.0, 1.0, 0.0])\n",
        "c = torch.linalg.cross(a, b)\n",
        "print(\"向量ab叉乘：\", c)"
      ],
      "metadata": {
        "id": "WS_lPoDjCL3_",
        "outputId": "9c11b474-7947-467d-9c1d-ba03553a039a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([ 1., -2., -3.]) 的绝对值张量： tensor([1., 2., 3.])\n",
            "张量x和它的绝对值不相等： False\n",
            "标准差： tensor(2.0817)\n",
            "X的范数： tensor(3.7417)\n",
            "AVG: tensor(3.5000) ,MAX: tensor(6.) ,MIN: tensor(1.)\n",
            "正态分布随机数： tensor([ 1.9505,  0.0249, -0.0648])\n",
            "向量ab叉乘： tensor([0., 0., 1.])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 张量API"
      ],
      "metadata": {
        "id": "4I7xHWtyntdm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "# 将numpy张量转换成torch张量\n",
        "x = torch.torch.from_numpy(np.array([-1, -2, -3])).float()\n",
        "#也可以把torch张量转为np张量\n",
        "x_np = x.numpy()\n",
        "\n",
        "# 创建一个张量\n",
        "x = torch.tensor([1, 2, 3])\n",
        "x = torch.zeros(3, 3)  # 创建全0张量\n",
        "x = torch.ones(3, 3) # 创建全1张量\n",
        "x = torch.rand(3, 3) # 创建一个元素在 [0, 1) 区间均匀分布的张量。\n",
        "x = torch.randn(3, 3) #  创建一个元素服从标准正态分布的张量。\n",
        "x = torch.arange(0, 10, 2) # 创建一个包含指定范围值[0，10]的一维向量,步长为2\n",
        "x = torch.linspace(0, 10, steps=5) # 创建0-10的5个元素 步长=(10-0)/5\n",
        "\n",
        "\n",
        "# 张量的转置\n",
        "x = torch.ones(4, 3)\n",
        "a_t = torch.transpose(x, 0, 1)\n",
        "print(x.shape, a_t.shape)\n",
        "\n",
        "# 切片操作（Slicing）\n",
        "y = x[:, 1]\n",
        "print(y.is_contiguous())  #是否在内存中连续\n",
        "\n",
        "# view展平\n",
        "y = x.view(-1)\n",
        "print(\"x展平为一阶向量：\",y)\n",
        "\n",
        "\n",
        "# 交换维度顺序\n",
        "y = x.permute(1, 0)\n",
        "print(y.shape)\n",
        "\n",
        "# 改变张量的形状\n",
        "y = x.reshape(2, 6)\n",
        "print(y.shape)\n",
        "\n",
        "# 自动求导\n",
        "x = torch.randn(2, 3, requires_grad=True) # 使张量支持梯度计算。\n",
        "y = x.sum()\n",
        "y.backward()  # 反向传播，计算梯度"
      ],
      "metadata": {
        "id": "x6yNhchInwrs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f7c500cb-3c41-49da-e09e-0943c4258d5a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([4, 3]) torch.Size([3, 4])\n",
            "False\n",
            "x展平为一阶向量： tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.])\n",
            "torch.Size([3, 4])\n",
            "torch.Size([2, 6])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 张量的设备与存储"
      ],
      "metadata": {
        "id": "Ye930oxQM3Pe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 设置 PyTorch 运算所使用的线程数（多线程加速 CPU 运算）\n",
        "torch.set_num_threads(4)\n",
        "\n",
        "x = torch.tensor([[4.0, 1.0], [5.0, 3.0], [2.0, 1.0]], device='cpu')\n",
        "print(\"存储在\", x.device)\n",
        "# 转移到gpu\n",
        "# x_gpu = x.to(\"cuda\")\n",
        "# print(\"是否存储在GPU\", x_gpu.is_cuda)\n",
        "\n",
        "x = x.storage()\n",
        "print(x)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C84_CzOfDEIo",
        "outputId": "692ea985-2b97-46e6-cb7f-482c7e02cdcf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "存储在 cpu\n",
            " 4.0\n",
            " 1.0\n",
            " 5.0\n",
            " 3.0\n",
            " 2.0\n",
            " 1.0\n",
            "[torch.storage.TypedStorage(dtype=torch.float32, device=cpu) of size 6]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 张量的序列化"
      ],
      "metadata": {
        "id": "cRqrHpyCOSft"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 张量的保存与加载\n",
        "x = torch.tensor([1, 2, 3])\n",
        "torch.save(x, 'tensor.pt')\n",
        "x = torch.load('tensor.pt')"
      ],
      "metadata": {
        "id": "gokCBshuCjhy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 用 h5py 序列化到 HDF5\n",
        "import h5py\n",
        "f = h5py.File('./data/p1ch3/ourpoints.hdf5', 'w')\n",
        "dset = f.create_dataset('coords',data=points.numpy())\n",
        "f.close()\n",
        "\n",
        "f = h5py.File('../data/p1ch3/ourpoints.hdf5', 'r')\n",
        "dset = f['coords']\n",
        "last_points = dset[-2:]\n",
        "last_points = torch.from_numpy(dset[-2:])\n",
        "f.close()"
      ],
      "metadata": {
        "id": "X0RGAug-OljX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 自动微分"
      ],
      "metadata": {
        "id": "qDs2ZvwbIyx3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 梯度跟踪"
      ],
      "metadata": {
        "id": "iTjZpqmIKBLt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "# 创建一个需要梯度的张量\n",
        "x = torch.tensor(2.0, requires_grad=True)\n",
        "y = x ** 2  # y = x^2\n",
        "\n",
        "# 计算梯度\n",
        "y.backward()  # dy/dx = 2x\n",
        "print(x.grad)  # 输出: tensor(4.) (因为 x=2, 2*2=4)"
      ],
      "metadata": {
        "id": "LHoV0uZfI7ux",
        "outputId": "a446b73a-f323-4c45-8cf4-09c1a0e176d4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(4.)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 多变量梯度"
      ],
      "metadata": {
        "id": "r7CBXmS0J5x4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x = torch.tensor([1.0, 2.0], requires_grad=True)\n",
        "y = x.sum() ** 2  # y = (x1 + x2)^2\n",
        "\n",
        "y.backward()\n",
        "print(x.grad)  # x^2的导数是2x， 2*（1+2）=6"
      ],
      "metadata": {
        "id": "9R19hSRSJ9q3",
        "outputId": "a4f14946-3dba-4b58-d825-69c8c4a61927",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([6., 6.])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 动态计算图\n",
        "PyTorch 的计算图是动态的，每次前向传播都会构建一个新图："
      ],
      "metadata": {
        "id": "NUbiWp5fKnEx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def forward(x):\n",
        "    return x ** 2 + 2 * x + 1\n",
        "\n",
        "x = torch.tensor(3.0, requires_grad=True)\n",
        "y = forward(x)\n",
        "y.backward()\n",
        "print(x.grad)  # 输出: tensor(8.) (因为 dy/dx=2x+2=8)"
      ],
      "metadata": {
        "id": "ICadJOHyK9wC",
        "outputId": "bcfd0a96-131b-43da-a9e2-39f47f08e268",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(8.)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 梯度积累 与 清零\n",
        "PyTorch 默认会累加梯度，训练时需手动清零："
      ],
      "metadata": {
        "id": "WnhWBm51LK3X"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x = torch.tensor(1.0, requires_grad=True)\n",
        "\n",
        "# 第一次计算\n",
        "y1 = x ** 2\n",
        "y1.backward()\n",
        "print(x.grad)  # tensor(2.)  2*x\n",
        "\n",
        "# 清零梯度\n",
        "# x.grad.zero_()\n",
        "\n",
        "# 第二次计算（梯度会累加）\n",
        "y2 = x ** 3\n",
        "y2.backward()\n",
        "print(x.grad)  # tensor(5.) 没清0: (2*1 + 3*1^2=5)； 梯度清过0: 3*1^2=3\n",
        "\n",
        "# 清零梯度\n",
        "x.grad.zero_()"
      ],
      "metadata": {
        "id": "Ehi8a7ifLRag",
        "outputId": "80f06551-c1a7-435e-88e5-010297c2ccfc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(2.)\n",
            "tensor(5.)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(0.)"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 阻止梯度跟踪\n",
        "\n",
        "detach() 分离张量，使其不参与梯度计算：\n",
        "\n",
        "``` python\n",
        "x = torch.tensor(2.0, requires_grad=True)\n",
        "y = x ** 2\n",
        "z = y.detach()  # z 不参与梯度计算\n",
        "\n",
        "z.backward()  # 报错！z 无梯度跟踪\n",
        "```\n",
        "\n",
        "临时禁用梯度计算：\n",
        "\n",
        "``` python\n",
        "x = torch.tensor(2.0, requires_grad=True)\n",
        "with torch.no_grad():\n",
        "    y = x ** 2  # y 不记录计算图\n",
        "```"
      ],
      "metadata": {
        "id": "L3ZBfw3TNdEO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 高阶导数"
      ],
      "metadata": {
        "id": "Po9bYtaSQr8t"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x = torch.tensor(2.0, requires_grad=True)\n",
        "y = x ** 3\n",
        "\n",
        "# 一阶导数\n",
        "grad1 = torch.autograd.grad(y, x, create_graph=True)  # dy/dx=3x^2=12\n",
        "print(grad1[0])  # tensor(12.)\n",
        "\n",
        "# 二阶导数\n",
        "grad2 = torch.autograd.grad(grad1[0], x)  # d²y/dx²=3*2x=12\n",
        "print(grad2[0])  # tensor(12.)"
      ],
      "metadata": {
        "id": "9ANS6aZzQrkU",
        "outputId": "4252bb47-2444-4ba9-b781-915227ba5415",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(12., grad_fn=<MulBackward0>)\n",
            "tensor(12.)\n"
          ]
        }
      ]
    }
  ]
}