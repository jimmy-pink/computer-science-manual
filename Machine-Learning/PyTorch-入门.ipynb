{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jimmy-pink/computer-science-manual/blob/main/Machine-Learning/PyTorch-%E5%85%A5%E9%97%A8.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "QaZ_xmJ9biey"
      },
      "cell_type": "markdown",
      "source": [
        "## 张量 Tensor\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "# 标量 0d\n",
        "x_0 = 3.14\n",
        "print(\"标量：\", x_0)\n",
        "# 向量 1d\n",
        "x = torch.arange(6)\n",
        "x_ones = torch.ones(3)\n",
        "x_zeros = torch.zeros(3)\n",
        "print(\"向量：\", x, \"，全一向量\", x_ones, \"，零向量：\", x_zeros)\n",
        "# 矩阵 2d\n",
        "X = torch.tensor([[1,2,3,4],[5,6,7,8]],dtype=torch.int)\n",
        "print(\"矩阵：\", X)\n",
        "# 3阶张量\n",
        "rgb_tensor = torch.tensor([\n",
        "    [[255,   0],  [  0, 255]],  # R通道（红色值）\n",
        "    [[  0, 255],  [255,   0]],  # G通道（绿色值）\n",
        "    [[  0,   0],  [255, 255]],  # B通道（蓝色值）\n",
        "], dtype=torch.uint8)\n",
        "print(\"3阶张量的shape: \", rgb_tensor.shape)\n",
        "print(\"3阶张量：\", rgb_tensor)"
      ],
      "metadata": {
        "id": "-rsiK0NqboJY",
        "outputId": "99fd592a-bb7d-43b1-e39d-5f29ec5881b8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "标量： 3.14\n",
            "向量： tensor([0, 1, 2, 3, 4, 5]) ，全一向量 tensor([1., 1., 1.]) ，零向量： tensor([0., 0., 0.])\n",
            "矩阵： tensor([[1, 2, 3, 4],\n",
            "        [5, 6, 7, 8]], dtype=torch.int32)\n",
            "3阶张量的shape:  torch.Size([3, 2, 2])\n",
            "3阶张量： tensor([[[255,   0],\n",
            "         [  0, 255]],\n",
            "\n",
            "        [[  0, 255],\n",
            "         [255,   0]],\n",
            "\n",
            "        [[  0,   0],\n",
            "         [255, 255]]], dtype=torch.uint8)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 访问张量的元素或子集\n",
        "\n",
        "四阶张量的命名： batch, channels, rows, columns"
      ],
      "metadata": {
        "id": "0FdDYvqbjWcU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "img_t = torch.randn(4, 5, 5) # shape [channels, rows, columns]\n",
        "\n",
        "print(\"访问向量的第2个元素：\", x[2])\n",
        "print(\"访问矩阵第1行第2列那个元素：\", X[1][2])\n",
        "print(\"访问颜色张量第2通道第1行第1列那个元素：\", rgb_tensor[2,1,1])\n",
        "print(\"访问颜色张量的一块连续子区域：\", rgb_tensor[1:3,0:2])\n",
        "print(\"3阶张量：\", img_t)\n",
        "print(\"访问3阶张量的一块不连续子区域：\", img_t[0:4:3,1:5:2,1:5:2])"
      ],
      "metadata": {
        "id": "JN7ZVHLKjbrq",
        "outputId": "4e20155b-14e4-4f2b-ad99-2f4d96b54e67",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "访问向量的第2个元素： tensor(2)\n",
            "访问矩阵第1行第2列那个元素： tensor(7, dtype=torch.int32)\n",
            "访问颜色张量第2通道第1行第1列那个元素： tensor(255, dtype=torch.uint8)\n",
            "访问颜色张量的一块连续子区域： tensor([[[  0, 255],\n",
            "         [255,   0]],\n",
            "\n",
            "        [[  0,   0],\n",
            "         [255, 255]]], dtype=torch.uint8)\n",
            "3阶张量： tensor([[[ 0.9202, -1.1630, -0.4923, -0.1636,  0.5016],\n",
            "         [ 0.6078, -0.8582, -0.6691, -0.6226,  1.0365],\n",
            "         [-0.0527,  0.1935,  0.5916, -0.2183, -0.6057],\n",
            "         [-0.6445,  1.8251, -1.0032, -1.0447, -0.6879],\n",
            "         [ 1.1997,  1.1389, -0.2753,  0.5477, -0.7883]],\n",
            "\n",
            "        [[ 0.4432, -0.4899,  0.3731,  0.1328, -0.9643],\n",
            "         [-1.0141, -0.7722, -1.8185, -1.2123, -0.9847],\n",
            "         [ 0.0165, -1.7033, -1.0640,  0.2721, -0.7622],\n",
            "         [ 0.8110,  0.5796,  0.0234,  0.8482, -0.6199],\n",
            "         [ 0.8966, -0.1763,  1.6681,  0.9645,  0.7777]],\n",
            "\n",
            "        [[ 0.2132, -1.0733,  0.9388, -0.7334,  1.0201],\n",
            "         [ 1.6030, -1.0971, -1.1210, -0.3910, -0.4873],\n",
            "         [ 0.4673, -2.1609, -0.7459,  0.8368,  0.2625],\n",
            "         [ 0.4929,  2.4086, -0.3815,  1.6580,  0.2748],\n",
            "         [ 0.8419,  0.2997,  0.0264,  0.5990, -0.3156]],\n",
            "\n",
            "        [[ 0.4763, -0.4029,  0.1709, -0.5032, -0.7573],\n",
            "         [-0.8849, -0.0906,  0.8794, -1.2921, -1.2309],\n",
            "         [ 1.2232, -0.4611,  0.8491,  0.2075,  0.0191],\n",
            "         [ 1.3429,  0.8814, -0.4187, -1.2038, -0.7311],\n",
            "         [-0.7238,  0.4405, -1.0320,  1.6181,  0.0138]]])\n",
            "访问3阶张量的一块不连续子区域： tensor([[[-0.8582, -0.6226],\n",
            "         [ 1.8251, -1.0447]],\n",
            "\n",
            "        [[-0.0906, -1.2921],\n",
            "         [ 0.8814, -1.2038]]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 张量API"
      ],
      "metadata": {
        "id": "4I7xHWtyntdm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 张量的转置\n",
        "a = torch.ones(3, 2)\n",
        "a_t = torch.transpose(a, 0, 1)\n",
        "print(a.shape)\n",
        "print(a_t.shape)"
      ],
      "metadata": {
        "id": "x6yNhchInwrs"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}